{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfa9ae6-69fe-444a-b994-8c4c5970a7ec",
   "metadata": {},
   "source": [
    "# Project - Airline AI Assistant\n",
    "\n",
    "We'll now bring together what we've learned to make an AI Customer Support assistant for an Airline\n",
    "\n",
    "Airline ticket by using multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b50bbe2-c0b1-49c3-9a5c-1ba7efa2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747e8786-9da8-4342-b6c9-f5f69c2e22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "# As an alternative, if you'd like to use Ollama instead of OpenAI\n",
    "# Check that Ollama is running for you locally (see week1/day2 exercise) then uncomment these next 2 lines\n",
    "# MODEL = \"llama3.2\"\n",
    "# openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a521d84-d07c-49ab-a0df-d6451499ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bedabf-a0a7-4985-ad8e-07ed6a55a3a4",
   "metadata": {},
   "source": [
    "## Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabbdb5-7f65-4616-867a-cd39bdabf774",
   "metadata": {},
   "source": [
    "There  will be 2 tools at the beginnig. \n",
    "1: Will tell the ticket price\n",
    "2. Will tell the places to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0696acb1-0b05-4dc2-80d5-771be04f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Ticket price function\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\") # this way we can see this function called in output\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\") # ticket_prices'te bulamazsa Unknown yazıyor\n",
    "    # return ticket_prices.get(city) # bu boş dönüyor bulamazsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ca4e09-6287-4d3f-997d-fa6afbcf6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ticket_price(\"Berlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afceded-7178-4c05-8fa6-9f2085e6a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "# 1st function for first tool\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price,\\\n",
    "                    for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb9edb7-08fb-496d-b62a-54e84a7d334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Places to see function\n",
    "\n",
    "places_to_see = {\"london\": \"London Eye\", \"paris\": \"Eifel\", \"tokyo\": \"Tokyo Drift\", \"berlin\": \"I don't know\", \\\n",
    "                \"istanbul\": \"Şükrü Saraçoğlu, Fenerbahçe Stadium\", \"bayburt\": \"Ortugu. \\\n",
    "                This place is where onur has born. Everybody should see there.\"}\n",
    "\n",
    "def get_places_to_see(destination_city): \n",
    "    print(f\"Tool get_places_to_see called for {destination_city}\") # this way we can see this function called in output\n",
    "    city = destination_city.lower()\n",
    "    return places_to_see.get(city, \"Bimiyorum ki valla Onur'a sor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79975363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_places_to_see(\"Ankara\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4db0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "# 2nd function for second tool\n",
    "\n",
    "place_function = {\n",
    "    \"name\": \"get_places_to_see\",\n",
    "    \"description\": \"Get the place to see in the destination city. \\\n",
    "                    Call this whenever you need to know the place to visit,\\\n",
    "                    for example when a customer asks 'Where can I visit in this city' or 'Where should I see in this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdca8679-935f-4e7f-97e6-e71a4d4f228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}, \n",
    "        {\"type\": \"function\", \"function\": place_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3554f-b4e3-4ce7-af6f-68faa6dd2340",
   "metadata": {},
   "source": [
    "## Getting OpenAI to use our Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce9b0744-9c78-408d-b9df-9f6fd9ed78cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def chat(message, history):\n",
    "#     messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "#     response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "#     print(f\"finish reason {response.choices[0].finish_reason}\")\n",
    "#     print(f\"Response {response.choices[0].message.content}\")\n",
    "\n",
    "#     if response.choices[0].finish_reason==\"tool_calls\":\n",
    "#         message = response.choices[0].message\n",
    "#         print(f\" \\n, Tool call message: {message}, \\n\")\n",
    "#         response, city = handle_tool_call(message)\n",
    "#         messages.append(message)\n",
    "#         messages.append(response)\n",
    "#         response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0992986-ea09-4912-a076-8e5603ee631f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0] # message already has which tool to call\n",
    "    arguments = json.loads(tool_call.function.arguments) # because it is in json format\n",
    "    city = arguments.get('destination_city')\n",
    "    function_name = tool_call.function.name # this is just a string, look at message(call tool message)\n",
    "    \n",
    "    # price = get_ticket_price(city) we dont know which function to use\n",
    "    func = 0\n",
    "    if function_name == \"get_ticket_price\":\n",
    "        price = get_ticket_price(city)\n",
    "        func = 1\n",
    "        tool_name = \"ticket_price\"\n",
    "        \n",
    "    elif function_name == \"get_places_to_see\":\n",
    "        place = get_places_to_see(city)\n",
    "        func = 2\n",
    "        tool_name = \"place_to_see\"\n",
    "        \n",
    "    if func == 1:\n",
    "        response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}), # destination_city tool call messagının içinde var\n",
    "        \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "    elif func == 2:\n",
    "        response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"place\": place}), # destination_city tool call messagının içinde var\n",
    "        \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "        \n",
    "    return response, city , tool_name\n",
    "    # i give tool_name s that if it is place_to_see it will draw the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4be8a71-b19e-4c2f-80df-f59ff2661f14",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gr.ChatInterface(fn=chat, type=\"messages\").launch()\n",
    "\n",
    "# # call id'de hata alıyor. şehir ismi verip taskı tam anlatmazsan karıştırıyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a2325-681c-477e-8d64-0b84cb59c383",
   "metadata": {},
   "source": [
    "# Let's go multi-modal!!\n",
    "\n",
    "We can use DALL-E-3, the image generation model behind GPT-4o, to make us some images\n",
    "\n",
    "Let's put this in a function called artist.\n",
    "\n",
    "### Price alert: each time I generate an image it costs about 4 cents - don't go crazy with images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16247b7-fd64-44d3-9e75-1535862434f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports for handling images\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc3450b-57e0-456c-8d7e-e340dc9af7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def artist(city):\n",
    "#     image_response = openai.images.generate(\n",
    "#             model=\"dall-e-2\", # dall-e-3\n",
    "#             prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "#             size=\"1024x1024\",\n",
    "#             n=1,\n",
    "#             response_format=\"b64_json\",\n",
    "#         )\n",
    "#     image_base64 = image_response.data[0].b64_json\n",
    "#     image_data = base64.b64decode(image_base64)\n",
    "#     return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b218f2a-9c08-4042-9aa7-babfb974dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = artist(\"İstanbul\")\n",
    "# display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a91525c0-3d6d-4d4b-8b67-26481aa9d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_call sonrası çizeceği şehir fotosuna place_to_see önerisini de dahil edecek.\n",
    "\n",
    "def artist(city, artist_place_input):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\", # dall-e-3\n",
    "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and \\\n",
    "            everything unique about {city}, in a vibrant pop-art style. Be creative and cool \\\n",
    "            Also if {artist_place_input} \\\n",
    "            is not None and there is a place suggested to visit, you must include that place \\\n",
    "            in the middle of theimage. For example if sugestion is to see Fenerbahçe Stadium, include \\\n",
    "            the stadium in the image. If it is Onur's hometown Ortugu then include Onur's home and village. \\\n",
    "            If there is no suggested place don't include it.\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d2266-2429-4c9b-9314-61e19be439e3",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2f5d007-c414-4e27-b4fe-ce8e7df64009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "libavutil      59. 39.100 / 59. 39.100\n",
      "libavcodec     61. 19.101 / 61. 19.101\n",
      "libavformat    61.  7.100 / 61.  7.100\n",
      "libavdevice    61.  3.100 / 61.  3.100\n",
      "libavfilter    10.  4.100 / 10.  4.100\n",
      "libswscale      8.  3.100 /  8.  3.100\n",
      "libswresample   5.  3.100 /  5.  3.100\n",
      "libpostproc    58.  3.100 / 58.  3.100\n",
      "ffprobe version 7.1.1 Copyright (c) 2007-2025 the FFmpeg developers\n",
      "built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "libavutil      59. 39.100 / 59. 39.100\n",
      "libavcodec     61. 19.101 / 61. 19.101\n",
      "libavformat    61.  7.100 / 61.  7.100\n",
      "libavdevice    61.  3.100 / 61.  3.100\n",
      "libavfilter    10.  4.100 / 10.  4.100\n",
      "libswscale      8.  3.100 /  8.  3.100\n",
      "libswresample   5.  3.100 /  5.  3.100\n",
      "libpostproc    58.  3.100 / 58.  3.100\n",
      "ffplay version 7.1.1 Copyright (c) 2003-2025 the FFmpeg developers\n",
      "built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "libavutil      59. 39.100 / 59. 39.100\n",
      "libavcodec     61. 19.101 / 61. 19.101\n",
      "libavformat    61.  7.100 / 61.  7.100\n",
      "libavdevice    61.  3.100 / 61.  3.100\n",
      "libavfilter    10.  4.100 / 10.  4.100\n",
      "libswscale      8.  3.100 /  8.  3.100\n",
      "libswresample   5.  3.100 /  5.  3.100\n",
      "libpostproc    58.  3.100 / 58.  3.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version\n",
    "!ffprobe -version\n",
    "!ffplay -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aa8d0f4-a229-4379-b790-f5710f4f7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f33a0a2c-e861-4338-aecb-00efd57e7964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/mf/fgc19wdn3pnglmlpk_yq8m2w0000gn/T/tmpl299dcnu.wav':\n",
      "  Duration: 00:00:00.84, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   0.71 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "talker(\"Well, hi there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247f44a-bd9d-4f14-9b54-137ef0bb332d",
   "metadata": {},
   "source": [
    "# Our Agent Framework\n",
    "\n",
    "The term 'Agentic AI' and Agentization is an umbrella term that refers to a number of techniques, such as:\n",
    "\n",
    "1. Breaking a complex problem into smaller steps, with multiple LLMs carrying out specialized tasks\n",
    "2. The ability for LLMs to use Tools to give them additional capabilities\n",
    "3. The 'Agent Environment' which allows Agents to collaborate\n",
    "4. An LLM can act as the Planner, dividing bigger tasks into smaller ones for the specialists\n",
    "5. The concept of an Agent having autonomy / agency, beyond just responding to a prompt - such as Memory\n",
    "\n",
    "We're showing 1 and 2 here, and to a lesser extent 3 and 5. In week 8 we will do the lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee13e979-1a05-4dad-bd62-225bb492ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city, tool_name = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        # image = artist(city)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        artist_place_input = response.choices[0].message.content\n",
    "        \n",
    "        if tool_name == \"place_to_see\":\n",
    "            image = artist(city, artist_place_input)\n",
    "\n",
    "        elif tool_name == \"ticket_price\":\n",
    "            image = None\n",
    "\n",
    "        artist_place_input = None\n",
    "\n",
    "        \n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    # Audio\n",
    "    talker(reply)\n",
    "    \n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16840bdc-b519-4635-825e-9b5aae4b5739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/mf/fgc19wdn3pnglmlpk_yq8m2w0000gn/T/tmpkxob3gov.wav':\n",
      "  Duration: 00:00:01.99, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   1.91 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool get_places_to_see called for Istanbul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/mf/fgc19wdn3pnglmlpk_yq8m2w0000gn/T/tmpz8h7t2jn.wav':\n",
      "  Duration: 00:00:02.90, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   2.88 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "# Passing in inbrowser=True in the last line will cause a Gradio window to pop up immediately.\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"You can write here :D\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
